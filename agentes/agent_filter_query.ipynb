{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e282aee6",
   "metadata": {},
   "source": [
    "# Agente - Query Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409c7a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi==0.112.2 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (0.112.2)\n",
      "Requirement already satisfied: uvicorn==0.30.5 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]==0.30.5->-r requirements.txt (line 2)) (0.30.5)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: pydantic==2.8.2 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: requests==2.32.3 in ./venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (2.32.3)\n",
      "Collecting openai (from -r requirements.txt (line 6))\n",
      "  Downloading openai-2.1.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in ./venv/lib/python3.13/site-packages (from fastapi==0.112.2->-r requirements.txt (line 1)) (0.38.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.13/site-packages (from fastapi==0.112.2->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic==2.8.2->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./venv/lib/python3.13/site-packages (from pydantic==2.8.2->-r requirements.txt (line 4)) (2.20.1)\n",
      "Requirement already satisfied: click>=7.0 in ./venv/lib/python3.13/site-packages (from uvicorn==0.30.5->uvicorn[standard]==0.30.5->-r requirements.txt (line 2)) (8.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in ./venv/lib/python3.13/site-packages (from uvicorn==0.30.5->uvicorn[standard]==0.30.5->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests==2.32.3->-r requirements.txt (line 5)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests==2.32.3->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests==2.32.3->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests==2.32.3->-r requirements.txt (line 5)) (2025.8.3)\n",
      "Requirement already satisfied: httptools>=0.5.0 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]==0.30.5->-r requirements.txt (line 2)) (0.6.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]==0.30.5->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]==0.30.5->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]==0.30.5->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./venv/lib/python3.13/site-packages (from uvicorn[standard]==0.30.5->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in ./venv/lib/python3.13/site-packages (from starlette<0.39.0,>=0.37.2->fastapi==0.112.2->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi==0.112.2->-r requirements.txt (line 1)) (1.3.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 6))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 6))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->-r requirements.txt (line 6))\n",
      "  Downloading jiter-0.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting tqdm>4 (from openai->-r requirements.txt (line 6))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 6))\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading openai-2.1.0-py3-none-any.whl (964 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m964.9/964.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.11.0-cp313-cp313-macosx_11_0_arm64.whl (314 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, httpcore, distro, httpx, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [openai]2m5/6\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.11.0 openai-2.1.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a0ae880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, Dict, Any\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e87665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_ROLE = \"\"\"  ====== INSTRUCCIONES ======\n",
    "Eres un asistente experto en el análisis de documentos legales de un consejo universitario. Tu función es analizar la pregunta de un usuario y convertirla en un objeto JSON estructurado con filtros para una base de datos.\n",
    "\n",
    "1.  **Analiza la pregunta:** Identifica fechas, rangos de tiempo, temas, nombres de personas, números de resolución, artículos y la intención principal del usuario (resumir, listar, explicar, etc.).\n",
    "2.  **Extrae fechas:** Si se menciona un mes y año (ej: \"marzo de 2025\"), calcula el rango de fechas completo (inicio: \"2025-03-01\", fin: \"2025-03-31\"). Si se mencionan términos relativos como \"hoy\", \"ayer\", \"último mes\", calcúlalo basado en la fecha actual.\n",
    "3.  **Normaliza el texto:** Convierte los temas y nombres a minúsculas para consistencia.\n",
    "4.  **Genera el JSON:** Devuelve ÚNICAMENTE el objeto JSON con los campos que lograste identificar. Si un campo no aplica, omítelo del JSON final.\n",
    "\n",
    "====== EJEMPLOS ======\n",
    "\n",
    "**Query:** ¿Qué resoluciones se aprobaron en el mes de marzo de 2025?\n",
    "**JSON:**\n",
    "{\n",
    "  \"rango_fechas\": {\n",
    "    \"fecha_inicio\": \"2025-03-01\",\n",
    "    \"fecha_fin\": \"2025-03-31\"\n",
    "  },\n",
    "  \"tipo_documento\": \"resolucion\",\n",
    "  \"intencion_usuario\": \"listar\"\n",
    "}\n",
    "\n",
    "**Query:** Resume las resoluciones relacionadas con reposición de títulos\n",
    "**JSON:**\n",
    "{\n",
    "  \"temas_principales\": [\"reposicion de titulos\"],\n",
    "  \"tipo_documento\": \"resolucion\",\n",
    "  \"intencion_usuario\": \"resumir\"\n",
    "}\n",
    "\n",
    "**Query:** ¿Por qué NO se aceptó el recurso de impugnación interpuesto por el Msc. Pablo Isaías Lazo Pillaga?\n",
    "**JSON:**\n",
    "{\n",
    "  \"temas_principales\": [\"recurso de impugnacion\"],\n",
    "  \"nombres_involucrados\": [\"pablo isaias lazo pillaga\"],\n",
    "  \"estado_proceso\": \"no aceptado\",\n",
    "  \"intencion_usuario\": \"explicar_motivo\"\n",
    "}\n",
    "====== FORMATO COMPLETO DE SALIDA ESPERADA ======\n",
    "{\n",
    "  \"rango_fechas\": {\n",
    "    \"fecha_inicio\": \"YYYY-MM-DD\", // Formato ISO 8601 para facilitar consultas\n",
    "    \"fecha_fin\": \"YYYY-MM-DD\"\n",
    "  },\n",
    "  \"temas_principales\": [], // Para conceptos clave como \"reposición de títulos\", \"impugnación\"\n",
    "  \"nombres_involucrados\": [], // Para personas o entidades como \"Msc. Pablo Isaías Lazo Pillaga\"\n",
    "  \"numeros_referencia\": {\n",
    "    \"id_resolucion\": \"\", // Si el usuario menciona un ID exacto\n",
    "    \"articulos\": [] // Si pregunta por artículos específicos\n",
    "  },\n",
    "  \"tipo_documento\": \"resolucion\", // Podría expandirse a \"acta\", \"informe\", etc.\n",
    "  \"estado_proceso\": \"\", // Para queries como \"¿cuál fue el resultado de...?\", \"aceptado\", \"negado\"\n",
    "  \"intencion_usuario\": \"resumir\" // Captura la acción: \"resumir\", \"listar\", \"explicar_motivo\", \"buscar_especifico\"\n",
    "}\n",
    "Nota: Lo que no encuentres usa None, no dejes como cadena de caracteres, ni uses null\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34170b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings \n",
    "client = OpenAI(base_url=\"http://127.0.0.1:1234\",api_key=\"not-needed\")\n",
    "app = FastAPI(\n",
    "    title=\"Query-Filter\",\n",
    "    description=\"promt detect filter\",\n",
    "    version=\"1.0.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c7640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromtRequest(BaseModel):\n",
    "    promt: str\n",
    "    max_tokens: int = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8259abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#end-point\n",
    "@app.post(\"/query-filters\")\n",
    "async def query_filters(request: PromtRequest):\n",
    "    \"\"\"\n",
    "    Recibe un promt y devuelve los filtros que ayudan a buscar mejor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model= \"local-model\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"{SYSTEM_ROLE}\"},\n",
    "                {\"role\": \"user\", \"content\": request.promt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=request.max_tokens,\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        return {response}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"No se pudo conectar con LM Studio. Asegúrate de que el servidor esté activo. Detalle: {str(e)}\"}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
